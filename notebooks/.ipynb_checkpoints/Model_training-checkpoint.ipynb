{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1c7d1c-9ccd-41d7-bc5d-e1688808195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bdc918-6e2d-49d2-abdd-8b8798e7f107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hp\\\\Pictures\\\\Big_mart_sales'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the directory\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc443387-571f-4d45-987e-d0b281ab1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('notebooks/pickle and trained data/preprocessed_train_data.csv')\n",
    "test_data=pd.read_csv('notebooks/pickle and trained data/preprocessed_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179eaebf-072d-4de5-8a32-7a267ddeefa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_data.drop(['Item_Outlet_Sales'],axis=1)\n",
    "train_y=train_data['Item_Outlet_Sales']\n",
    "test_x=test_data.drop(['Item_Outlet_Sales'],axis=1)\n",
    "test_y=test_data['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e79c1c-3b38-43eb-88d1-c17622e94648",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17142888-0fd9-4f28-a3d7-c79e2fbe40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor , HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error,r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d2f434-4f4c-463a-9793-0f824393afd6",
   "metadata": {},
   "source": [
    "## Model_Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e9814fc-1b46-496c-a002-132b0d8e32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ea692a7-49f7-4d60-8579-3d810e22c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_predict(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train the model on training data, make predictions on both training and test datasets,\n",
    "    and calculate the error metrics (RMSE and R²).\n",
    "\n",
    "    Args:\n",
    "        model: The machine learning model to be trained.\n",
    "        X_train: Features of the training set.\n",
    "        y_train: Target variable of the training set.\n",
    "        X_test: Features of the test set.\n",
    "        y_test: Target variable of the test set.\n",
    "\n",
    "    Returns:\n",
    "        y_train_pred: Predictions for the training set.\n",
    "        y_test_pred: Predictions for the test set.\n",
    "        model: The trained model.\n",
    "        train_rmse: RMSE for the training set.\n",
    "        test_rmse: RMSE for the test set.\n",
    "        train_r2: R² for the training set.\n",
    "        test_r2: R² for the test set.\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on training and test data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    train_rmse = rmse(y_train, y_train_pred)\n",
    "    test_rmse = rmse(y_test, y_test_pred)\n",
    "\n",
    "    # Calculate R² score\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print error metrics\n",
    "    print(f\"Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"Train R²: {train_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
    "\n",
    "    # Return predictions, error metrics, and trained model\n",
    "    return y_train_pred, y_test_pred, model, train_rmse, test_rmse, train_r2, test_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9fc4ecc-6361-4b7f-8cb6-fd16b25cf9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1141.4831, Test RMSE: 1069.8566\n",
      "Train R²: 0.5595, Test R²: 0.5789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2915.30213996, 2664.7137757 , 1784.63942699, ..., 3741.07278809,\n",
       "        1938.53858874, 1534.80940478]),\n",
       " array([1377.22583145,  698.24683611,  890.61037116, ...,  859.72309159,\n",
       "         574.13183474, 1712.60659923]),\n",
       " LinearRegression(),\n",
       " 1141.4830894243353,\n",
       " 1069.8566182690477,\n",
       " 0.5595126723576831,\n",
       " 0.5788794005819018)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_predict(LinearRegression(), train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb22813d-fa4e-4dd0-8db3-a368e9ecb185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.0000, Test RMSE: 1521.1544\n",
      "Train R²: 1.0000, Test R²: 0.1487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2386.2272, 3103.9596, 1125.202 , ..., 6145.334 , 1649.8524,\n",
       "         965.41  ]),\n",
       " array([ 402.809 ,  479.376 , 1216.4166, ..., 1216.4166,  377.5086,\n",
       "        1310.2944]),\n",
       " DecisionTreeRegressor(),\n",
       " 0.0,\n",
       " 1521.1544363962473,\n",
       " 1.0,\n",
       " 0.1486621402537014)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_predict(DecisionTreeRegressor(), train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c85c67-1589-4e47-a550-b2ae042c8ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 425.9158, Test RMSE: 1072.6443\n",
      "Train R²: 0.9387, Test R²: 0.5767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2607.07306 , 2981.339214, 1382.247406, ..., 5444.326496,\n",
       "        1659.286786, 1186.795158]),\n",
       " array([ 959.610882,  787.74127 ,  822.709086, ...,  801.676464,\n",
       "         648.595728, 1441.543554]),\n",
       " RandomForestRegressor(),\n",
       " 425.91580300693914,\n",
       " 1072.6442579348127,\n",
       " 0.9386743777878829,\n",
       " 0.5766819810812974)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_and_predict(RandomForestRegressor(), train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e5150ed-3a56-4bfe-90fe-a072dbdb9124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1039.6103, Test RMSE: 1037.7474\n",
      "Train R²: 0.6346, Test R²: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2949.18867694, 2841.29234574, 1661.25824279, ..., 3944.53067851,\n",
       "        1910.18316175, 1533.01836422]),\n",
       " array([1343.96538953,  691.79510098,  765.37105818, ...,  749.72991684,\n",
       "         673.92624331, 1643.55905564]),\n",
       " GradientBoostingRegressor(),\n",
       " 1039.6103175225023,\n",
       " 1037.7473737701903,\n",
       " 0.6346277019965068,\n",
       " 0.6037779720262129)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_predict(GradientBoostingRegressor(), train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20fb0a2d-397a-4dd0-9ca6-878d99a136f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1251.4736, Test RMSE: 1212.6141\n",
      "Train R²: 0.4705, Test R²: 0.4590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3429.77864852, 3215.6378298 , 1982.60245967, ..., 4346.37466204,\n",
       "        2281.27757662, 1760.94703754]),\n",
       " array([1447.48700183, 1165.65458428, 1165.65458428, ..., 1165.65458428,\n",
       "        1056.3068431 , 2145.61856422]),\n",
       " AdaBoostRegressor(),\n",
       " 1251.473605045952,\n",
       " 1212.6141219545245,\n",
       " 0.4705342846714349,\n",
       " 0.45899587827546984)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_predict(AdaBoostRegressor(), train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "581feb27-5e29-42e0-94f0-cd51d43e9e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 553.3589, Test RMSE: 1111.7636\n",
      "Train R²: 0.8965, Test R²: 0.5452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2736.5752, 3134.9272, 1414.7827, ..., 5176.3335, 1529.4888,\n",
       "        1664.8395], dtype=float32),\n",
       " array([1214.5975 ,  965.4787 ,  945.63153, ...,  656.35474, 1196.7532 ,\n",
       "        1424.6592 ], dtype=float32),\n",
       " XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...),\n",
       " 553.3589116715312,\n",
       " 1111.7635893084725,\n",
       " 0.8964838117316453,\n",
       " 0.545242129891949)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_predict(XGBRegressor(), train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ac8b8fa-b907-457f-822f-226521fa0828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 869.1222, Test RMSE: 1058.6668\n",
      "Train R²: 0.7446, Test R²: 0.5876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2758.99564753, 2724.45234126, 1705.57635672, ..., 4909.43097167,\n",
       "        1833.85219885, 1537.44444293]),\n",
       " array([1248.91897069,  683.43599501,  694.3247244 , ...,  786.04042542,\n",
       "         603.133507  , 1608.23357731]),\n",
       " HistGradientBoostingRegressor(),\n",
       " 869.1221711443889,\n",
       " 1058.6668326626077,\n",
       " 0.7446380932926133,\n",
       " 0.5876424555421988)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_and_predict(HistGradientBoostingRegressor(), train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c4822-6e8c-47a6-8504-ab21cf83a43c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- we can say for above results Gradient boosting  is performing well compare to another models so we tune the model for better results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3621a4cf-000e-4071-b1d1-aa18c73d9aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingRegressor must be a str among {'quantile', 'huber', 'absolute_error', 'squared_error'}. Got 'ls' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\hp\\anaconda3.x\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [-1492202.61436699 -1438676.92724795               nan               nan\n",
      " -1352390.63067581               nan               nan               nan\n",
      " -1272818.68580423 -1299089.61534934]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'subsample': 0.8, 'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': None, 'max_depth': 5, 'loss': 'huber', 'learning_rate': 0.2}\n",
      "Test RMSE: 1045.9663190881909\n"
     ]
    }
   ],
   "source": [
    "# Define the GradientBoostingRegressor model\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "# Define the hyperparameter grid to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'loss': ['ls', 'huber', 'absolute_error']\n",
    "}\n",
    "# Set up randomSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=gbr, param_distributions=param_grid,n_iter=10, cv=5, verbose=2, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit random search\n",
    "random_search.fit(train_x, train_y)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Evaluate on test data\n",
    "test_rmse = np.sqrt(-random_search.score(test_x,test_y))  # RMSE from neg_mean_squared_error scoring\n",
    "print(f'Test RMSE: {test_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f3780-e5ae-4f7e-b578-3107a4f0e051",
   "metadata": {},
   "source": [
    "random forest:Best Hyperparameters: {'bootstrap': True, 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\r\n",
    "Test RMSE: 1049.931056226055\n",
    "\n",
    "gradient boosting=Best Hyperparameters: {'subsample': 0.8, 'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'max_depth': 9, 'loss': 'absolute_error', 'learning_rate': 0.2}\r\n",
    "Test RMSE: 1064.0094990492717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2139a68-b516-4e12-b303-59595d2a6e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 969.5338911471888\n",
      "Train R²: 0.6822244752046414\n",
      "Test RMSE: 1057.6249115445685\n",
      "Test R²: 0.5884537260882967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the GradientBoostingRegressor with the specified hyperparameters\n",
    "gbr = GradientBoostingRegressor(\n",
    "    'bootstrap'=True,\n",
    "    'max_depth'= 30,\n",
    "    'max_features'= 'log2',\n",
    "    'min_samples_leaf'= 2,\n",
    "    'min_samples_split'= 2,\n",
    "    'n_estimators'= 100\n",
    ") \n",
    "\n",
    "# Fit the model on the training data\n",
    "gbr.fit(train_x, train_y)\n",
    "\n",
    "# Predict on training data\n",
    "predict_value_train = gbr.predict(train_x)\n",
    "\n",
    "# Calculate RMSE and R² on the training data\n",
    "train_rmse = np.sqrt(mean_squared_error(train_y, predict_value_train))\n",
    "train_r2 = r2_score(train_y, predict_value_train)\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Train R²: {train_r2}')\n",
    "\n",
    "# Predict on test data\n",
    "test_predict = gbr.predict(test_x)\n",
    "\n",
    "# Calculate RMSE and R² on the test data (assuming you have test_y as the true values)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_y, test_predict))\n",
    "test_r2 = r2_score(test_y, test_predict)\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "print(f'Test R²: {test_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3f357af-d83a-4b00-97e1-ac1ae95bfc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 763.4573659491014\n",
      "Train R²: 0.8029556284917818\n",
      "Test RMSE: 1046.9612959680212\n",
      "Test R²: 0.5967108068193415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the GradientBoostingRegressor with the specified hyperparameters\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,                # Number of trees in the forest\n",
    "    min_samples_split=2,            # Minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=2,            # Minimum number of samples required at each leaf node\n",
    "    max_features='log2',            # Number of features to consider for the best split\n",
    "    max_depth=30,                    # Maximum depth of the tree\n",
    "    bootstrap=True                  # Whether to use bootstrap samples\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "# Predict on training data\n",
    "predict_value_train =rf.predict(train_x)\n",
    "\n",
    "# Calculate RMSE and R² on the training data\n",
    "train_rmse = np.sqrt(mean_squared_error(train_y, predict_value_train))\n",
    "train_r2 = r2_score(train_y, predict_value_train)\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Train R²: {train_r2}')\n",
    "\n",
    "# Predict on test data\n",
    "test_predict = rf.predict(test_x)\n",
    "\n",
    "# Calculate RMSE and R² on the test data (assuming you have test_y as the true values)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_y, test_predict))\n",
    "test_r2 = r2_score(test_y, test_predict)\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "print(f'Test R²: {test_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68df829-8266-4d72-b9a7-5c9fd77a4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=659, max_depth=5, min_samples_split=7, min_samples_leaf=5, \n",
    "                                       oob_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b521e0b0-52e6-477d-9711-0c6683d3bb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1064.8398556270176\n",
      "Train R²: 0.6166786133744738\n",
      "Test RMSE: 1019.1116866000187\n",
      "Test R²: 0.6178807697254921\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GradientBoostingRegressor with the specified hyperparameters\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=659, max_depth=5, min_samples_split=7, min_samples_leaf=5, \n",
    "                                       oob_score=True, n_jobs=-1)                 \n",
    "\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "# Predict on training data\n",
    "predict_value_train =rf.predict(train_x)\n",
    "\n",
    "# Calculate RMSE and R² on the training data\n",
    "train_rmse = np.sqrt(mean_squared_error(train_y, predict_value_train))\n",
    "train_r2 = r2_score(train_y, predict_value_train)\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Train R²: {train_r2}')\n",
    "\n",
    "# Predict on test data\n",
    "test_predict = rf.predict(test_x)\n",
    "\n",
    "# Calculate RMSE and R² on the test data (assuming you have test_y as the true values)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_y, test_predict))\n",
    "test_r2 = r2_score(test_y, test_predict)\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "print(f'Test R²: {test_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90ccfa70-adee-45b8-a961-118e505bb9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 987.6750148843141\n",
      "Train R²: 0.6702213088916251\n",
      "Test RMSE: 1044.0149504806225\n",
      "Test R²: 0.5989774757954465\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the GradientBoostingRegressor with the specified hyperparameters\n",
    "gbr = GradientBoostingRegressor(n_estimators=533, learning_rate=.0214, max_depth=4, min_samples_leaf=4,min_samples_split=3)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gbr.fit(train_x, train_y)\n",
    "\n",
    "# Predict on training data\n",
    "predict_value_train = gbr.predict(train_x)\n",
    "\n",
    "# Calculate RMSE and R² on the training data\n",
    "train_rmse = np.sqrt(mean_squared_error(train_y, predict_value_train))\n",
    "train_r2 = r2_score(train_y, predict_value_train)\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Train R²: {train_r2}')\n",
    "\n",
    "# Predict on test data\n",
    "test_predict = gbr.predict(test_x)\n",
    "\n",
    "# Calculate RMSE and R² on the test data (assuming you have test_y as the true values)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_y, test_predict))\n",
    "test_r2 = r2_score(test_y, test_predict)\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "print(f'Test R²: {test_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287962f-dd58-4a25-8708-6712bfdc6d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
